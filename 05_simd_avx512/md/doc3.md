
---

# 第 5 章：SIMD vs GPU SIMT 的架构哲学差异

## —— 两种并行世界观的根本分歧

---

## 5.1 并行计算的两条主线

现代高性能计算并行，本质只有两条路线：

```
                并行计算
                    |
        --------------------------------
        |                              |
   数据级并行（DLP）             线程级并行（TLP）
        |                              |
      SIMD                           SIMT
```

* **SIMD**：CPU 的答案
* **SIMT**：GPU 的答案

它们不是“性能强弱”的问题，而是**世界观不同**。

---

## 5.2 SIMD 的架构哲学：扩展一条指令的“宽度”

### 5.2.1 SIMD 的第一性设计目标

> **在不改变程序语义的前提下，
> 让一条指令“吃掉”更多数据**

因此 SIMD 的设计核心是：

* 保持 **单线程语义**
* 保持 **强顺序一致性**
* 让并行对程序员“尽量透明”

---

### 5.2.2 SIMD 的执行模型（锁步）

```
          Vector Instruction
       -------------------------
       | lane0 | lane1 | ... |
       -------------------------
            ↑   ↑   ↑
          同一条指令
```

特征：

* 所有 lane **共享 PC**
* 无独立调度
* 无延迟隐藏

👉 **并行性是“被动的”**

---

### 5.2.3 SIMD 的隐含假设

SIMD 假设：

1. **分支很少**
2. **数据规则**
3. **内存局部性好**
4. **延迟可以接受**

这正是 CPU 程序的典型特征。

---

## 5.3 SIMT 的架构哲学：复制“线程”，而不是指令

### 5.3.1 SIMT 的根本动机

> **让硬件吞吐最大化，
> 哪怕牺牲单线程语义**

GPU 关心的是：

* 吞吐（Throughput）
* 延迟隐藏
* 大规模并行

---

### 5.3.2 SIMT 的执行模型（Warp / Wavefront）

```
Warp (32 threads)
  ├─ thread 0
  ├─ thread 1
  ├─ ...
  └─ thread 31
```

特征：

* 每个线程有 **独立寄存器 / PC**
* 硬件调度数千线程
* 延迟由 **切换 warp** 隐藏

👉 **并行性是“主动的”**

---

### 5.3.3 SIMT 的关键妥协

* 分支 → Warp divergence
* 内存 → 合并访问（coalescing）
* 同步 → barrier

GPU 接受这些复杂性，换取规模。

---

## 5.4 控制流处理的哲学对立

### SIMD：避免控制流

* 分支 → 掩码
* 条件 → predication

```c
_mm512_mask_add_ps(...)
```

> **控制流是“异常路径”**

---

### SIMT：允许但惩罚控制流

```cuda
if (cond) {
    ...
}
```

* Warp 内分歧
* 硬件串行化

> **控制流是“常态成本”**

---

### 本质差异

| 维度   | SIMD      | SIMT            |
| ---- | --------- | --------------- |
| 控制流  | 被压平       | 被串行             |
| 成本模型 | 掩码浪费 lane | divergence 浪费时间 |
| 设计目标 | 减少分支      | 接受分支            |

---

## 5.5 内存系统哲学差异

### 5.5.1 SIMD（CPU）的内存观

* Cache 层次复杂
* 预取器智能
* 单线程延迟敏感

> **追求低延迟**

---

### 5.5.2 SIMT（GPU）的内存观

* Cache 很浅
* 寄存器巨大
* 带宽极高

> **追求吞吐**

---

### 对比总结

| 特性    | SIMD | SIMT    |
| ----- | ---- | ------- |
| Cache | 深    | 浅       |
| 延迟隐藏  | 几乎无  | Warp 切换 |
| 带宽    | 中    | 极高      |

---

## 5.6 并行粒度与调度模型

### SIMD

* 粒度：lane
* 调度：指令级
* 程序员感知不到

### SIMT

* 粒度：线程
* 调度：Warp / SM
* 程序员必须管理

---

## 5.7 性能建模视角的根本不同

### SIMD 建模

[
Performance \approx \min(
Compute,,
Memory
)
]

* Roofline
* Port / µop
* Cache 命中

---

### SIMT 建模

[
Performance \approx
Occupancy
\times
Warp_Efficiency
\times
Memory_Throughput
]

* Occupancy
* Divergence
* Latency hiding

---

## 5.8 程序员心智模型对比

| 维度    | SIMD | SIMT |
| ----- | ---- | ---- |
| 思维方式  | 标量扩展 | 并行线程 |
| Debug | 容易   | 困难   |
| 性能调优  | 局部   | 系统性  |
| 可预测性  | 高    | 低    |

👉 **SIMD 更像“高级汇编”
SIMT 更像“并行操作系统”**

---

## 5.9 为什么深度学习两者都需要

### 推理（Inference）

* Batch 小
* 延迟敏感
* 控制复杂

👉 SIMD 胜出

---

### 训练（Training）

* Batch 大
* 吞吐敏感
* 规则计算

👉 SIMT 胜出

---

## 5.10 RISC-V V 与未来融合趋势

RISC-V V：

* 向量长度抽象
* 掩码即一等公民
* 更像 **“CPU 世界的 SIMT-lite”**

而 GPU：

* Tensor Core
* Warp-level MMA
* 正在向 **SIMD 内核化** 靠拢

---

## 5.11 终极总结：两种世界观

> **SIMD 是“让程序看起来仍是串行”
> SIMT 是“让程序承认自己是并行”**

它们不是竞争关系，而是：

* **CPU：控制 + 低延迟 + SIMD**
* **GPU：吞吐 + 大规模 + SIMT**

---

### 一句话工程判断法

* **规则、低延迟、复杂逻辑 → SIMD**
* **规则、吞吐优先、规模大 → SIMT**
* **两者兼有 → CPU + GPU 协同**

---

